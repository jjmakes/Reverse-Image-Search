{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "detect -> convoluted -> generate -> knn -> train -> test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Used to pad around extracted faces\n",
    "offset = 10\n",
    "\n",
    "# Initialize haar cascade filters provided by\n",
    "# https://github.com/opencv/opencv/tree/master/data/haarcascades\n",
    "face_cascade = cv2.CascadeClassifier(\"./haarcascades/haarcascade_frontalface_default.xml\")\n",
    "\n",
    "# Crop faces from photos\n",
    "def crop(photo_path):\n",
    "    \n",
    "    # Read Photo into the img var\n",
    "    img = cv2.imread(photo_path)\n",
    "    # cv2.imshow('photo', img)\n",
    " \n",
    "    # Apply grayscale to the image\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    " \n",
    "    # Face Detection\n",
    "    # Cascading params: image, scaleFactor, minNeighbors\n",
    "    face = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    " \n",
    "    if len(face) == 0:\n",
    "        return face\n",
    " \n",
    "    x,y,w,h = face[0]\n",
    " \n",
    "    # Drawing a rectangle around the face coordinates\n",
    "    # cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2) \n",
    " \n",
    "    # Slicing face from original image\n",
    "    face_cut = img[y-offset:y+h+offset,x-offset:x+w+offset]\n",
    "    if 0 in face_cut.shape:\n",
    "        return []\n",
    "    # Resizing faces to 128x128px\n",
    "    face_cut = cv2.resize(face_cut,(128,128))\n",
    "\n",
    "    # Display each face and wait for keypress before proceeding\n",
    "    # cv2.imshow('crop', face_cut)\n",
    "    # cv2.waitKey(0)\n",
    " \n",
    "    return face_cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edgy_af(img):\n",
    "    \"\"\"\n",
    "    Apply crop, edge detection, and grayscale filters to input image\n",
    "    \"\"\"\n",
    "\n",
    "    # Apply edge detection kernel\n",
    "    h_kernel = np.array(\n",
    "        [\n",
    "            [-1, 0, 1],\n",
    "            [-1, 0, 1],\n",
    "            [-1, 0, 1],\n",
    "        ]\n",
    "    )\n",
    "    v_kernel = np.array(\n",
    "        [\n",
    "            [-1, -1, -1],\n",
    "            [0, 0, 0],\n",
    "            [1, 1, 1],\n",
    "        ]\n",
    "    )\n",
    "    img = cv2.filter2D(src=img, ddepth=-1, kernel=h_kernel) + cv2.filter2D(\n",
    "        src=img, ddepth=-1, kernel=v_kernel\n",
    "    )\n",
    "\n",
    "    # Make grayscale\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Parse through a dataset to prepare face analysis\n",
    "img_dict = {}\n",
    "face_count = 0\n",
    "\n",
    "train_dir = \"samples\"\n",
    "dataset_path = \"dataset/\"\n",
    "\n",
    "for f_name in os.listdir(train_dir):\n",
    "    for p_img in os.listdir(os.path.join(train_dir, f_name)):\n",
    "        face_count += 1\n",
    "        if f_name in img_dict.keys():\n",
    "            img_dict[f_name].append(os.path.join(train_dir, f_name, p_img))\n",
    "        else:\n",
    "            img_dict[f_name] = [os.path.join(train_dir, f_name, p_img)]\n",
    "\n",
    "# Metrics for counting detected faces\n",
    "detect_count = 0\n",
    "\n",
    "# Looping through all image directory values\n",
    "for person in img_dict:\n",
    "\n",
    "    # Create a new array for person's images\n",
    "    face_data = []\n",
    "\n",
    "    for photo in img_dict[person]:\n",
    "\n",
    "        print(photo)\n",
    "\n",
    "        face_cut = crop(photo)\n",
    "\n",
    "        if len(face_cut) == 0:\n",
    "            continue\n",
    "\n",
    "        face_filter = edgy_af(face_cut)\n",
    "\n",
    "        detect_count += 1\n",
    "\n",
    "        # Add face data to array for dataset export\n",
    "        face_data.append(face_filter)\n",
    "\n",
    "    # Save the dataset\n",
    "    if len(face_data) == 0:\n",
    "        continue\n",
    "\n",
    "    # Converting data to np array and saving to /data\n",
    "    face_data = np.asarray(face_data)\n",
    "    face_data = face_data.reshape((face_data.shape[0], -1))\n",
    "    np.save(dataset_path + person + \".npy\", face_data)\n",
    "\n",
    "    print(\"Saved \" + person + \"'s data to /data\")\n",
    "\n",
    "print(\"Detected \" + str(detect_count / face_count * 100) + \"%\")\n",
    "print(\"(\" + str(detect_count) + \"/\" + str(face_count) + \")\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find distance between two euclidian values\n",
    "def distance(v1, v2):\n",
    "    return np.sqrt(((v1-v2)**2).sum())\n",
    "\n",
    "def predict(train, test, k=3):\n",
    "    dist = []\n",
    "\n",
    "    for i in range(train.shape[0]):\n",
    "        # Get vector and label\n",
    "        ix = train[i, :-1]\n",
    "        iy = train[i, -1]\n",
    "        print(test)\n",
    "        print(ix)\n",
    "        # Computing the distance from the test point\n",
    "        d = distance(test, ix)\n",
    "        dist.append([d,iy])\n",
    "    # Sort based on distance and get top k\n",
    "    dk = sorted(dist, key=lambda x: x[0])[:k]\n",
    "    # Retrieve only the labels\n",
    "    labels = np.array(dk)[:, -1]\n",
    "\n",
    "    # Get frequencies of each label\n",
    "    output = np.unique(labels, return_counts=True)\n",
    "    # Find max frequency and corresponding label\n",
    "    index = np.argmax(output[1])\n",
    "    return output[0][index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "dataset_path = 'dataset/'\n",
    "\n",
    "face_data = []\n",
    "labels = []\n",
    "\n",
    "class_id = 0 # Labels for the given file\n",
    "names = {} # Mapping id & name\n",
    "\n",
    "# Data Prep\n",
    "for fx in os.listdir(dataset_path):\n",
    "\n",
    "    if fx.endswith('.npy'):\n",
    "\n",
    "        # Create class_id & name mapping\n",
    "        names[class_id] = fx[:-4] # index removes .npy from name\n",
    "        print('Loaded ' + fx)\n",
    "\n",
    "        data_item = np.load(dataset_path+fx)\n",
    "        face_data.append(data_item)\n",
    "\n",
    "        # Create Labels for the class\n",
    "        target = class_id*np.ones((data_item.shape[0],))\n",
    "        class_id += 1\n",
    "        labels.append(target)\n",
    "\n",
    "face_dataset = np.concatenate(face_data,axis=0)\n",
    "face_labels = np.concatenate(labels,axis=0).reshape((-1,1))\n",
    "\n",
    "print(face_dataset.shape)\n",
    "print(face_labels.shape)\n",
    "\n",
    "trainset = np.concatenate((face_dataset,face_labels),axis=1)\n",
    "\n",
    "# Saving label names\n",
    "json_str = json.dumps(names)\n",
    "f = open('names.json', 'w')\n",
    "f.write(json_str)\n",
    "f.close()\n",
    "\n",
    "# Saving model\n",
    "np.save('model.npy', trainset)\n",
    "\n",
    "print(\"Model finished training and saved to model.npy.\\nShape:\\n\")\n",
    "\n",
    "print(trainset.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dir = 'tests'\n",
    "\n",
    "# Loading the datasets\n",
    "trainset = np.load('model.npy')\n",
    " \n",
    "f = open('names.json')\n",
    "names = json.load(f)\n",
    "f.close()\n",
    "\n",
    "for f_name in os.listdir(test_dir):\n",
    "    photo_path = test_dir + '/' + f_name\n",
    "    face_cut = crop(test_dir + '/' + f_name)\n",
    "\n",
    "    if len(face_cut) == 0:\n",
    "        print(f\"Face not detected in test image: {photo_path}.\\n\")\n",
    "        continue\n",
    "\n",
    "    face_filter = edgy_af(face_cut)\n",
    "\n",
    "    # Make face prediction\n",
    "    out = predict(trainset,face_filter.flatten())\n",
    "    pred_name = names[str(int(out))];\n",
    "\n",
    "    print(\"Image \" + photo_path + \" is predicted to be: \")\n",
    "    print(pred_name + \"\\n\")\n",
    "\n",
    "    cv2.imshow('tests', face_filter)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9fceb04c73eb57fe7631f74f063f9f6f7fd58a78b78ab48e8e5821942bc17e45"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
